{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T15:23:57.253969Z",
     "start_time": "2018-11-20T15:23:56.944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "println(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T15:23:59.421041Z",
     "start_time": "2018-11-20T15:23:59.015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres2\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"merrywivesofwindsor\"\u001b[39m,\n",
       "  \u001b[32m\"twelfthnight\"\u001b[39m,\n",
       "  \u001b[32m\"midsummersnightsdream\"\u001b[39m,\n",
       "  \u001b[32m\"loveslabourslost\"\u001b[39m,\n",
       "  \u001b[32m\"asyoulikeit\"\u001b[39m,\n",
       "  \u001b[32m\"comedyoferrors\"\u001b[39m,\n",
       "  \u001b[32m\"muchadoaboutnothing\"\u001b[39m,\n",
       "  \u001b[32m\"tamingoftheshrew\"\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new java.io.File(\"../data/shakespeare\").list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T15:52:31.540627Z",
     "start_time": "2018-11-20T15:52:31.172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd0.sc:3: object apache is not a member of package org\n",
      "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
      "                         ^cmd0.sc:3: not found: value sc\n",
      "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
      "                                                     ^cmd0.sc:1: not found: value %\n",
      "val res0_0 = %ShowTypes on\n",
      "             ^cmd0.sc:1: not found: value on\n",
      "val res0_0 = %ShowTypes on\n",
      "                        ^cmd0.sc:24: not found: value sc\n",
      "val res0_6 = println(\"Using Spark version \" + sc.version)\n",
      "                                              ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "%ShowTypes on\n",
    "\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "\n",
    "// For implicit transformation of RDDs to DataFrames\n",
    "import sqlContext.implicits._\n",
    "\n",
    "// For telling Spark to look in the local file system\n",
    "import java.io._\n",
    "def localpath(path: String): String = {\n",
    "    \"file://\" + new java.io.File(\".\").getCanonicalPath + \"/\" + path\n",
    "}\n",
    "\n",
    "// For timing expression evaluation\n",
    "def time[R](block: => R): R = {\n",
    "    val start: Long = System.nanoTime()\n",
    "    val result = block\n",
    "    val end: Long = System.nanoTime()\n",
    "    val duration: Double = (end - start) / 1000000000.0\n",
    "    println(\"Elapsed time: \" + duration + \"s\")\n",
    "    result\n",
    "}\n",
    "\n",
    "println(\"Using Spark version \" + sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T15:52:34.853269Z",
     "start_time": "2018-11-20T15:52:34.745Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd0.sc:2: object apache is not a member of package org\n",
      "import org.apache.spark.SparkConf\n",
      "           ^cmd0.sc:4: not found: type SparkConf\n",
      "val conf = new SparkConf().setAppName(\"Simple Application\")\n",
      "               ^cmd0.sc:1: object apache is not a member of package org\n",
      "import org.apache.spark.SparkContext\n",
      "           ^cmd0.sc:5: not found: type SparkContext\n",
      "val sc = new SparkContext(conf)\n",
      "             ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf\n",
    "\n",
    "val conf = new SparkConf().setAppName(\"Simple Application\")\n",
    "val sc = new SparkContext(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T15:24:06.206730Z",
     "start_time": "2018-11-20T15:24:06.144Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd3.sc:1: not found: value sc\n",
      "val res3 = sc\n",
      "           ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
